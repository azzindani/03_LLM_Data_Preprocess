[![Gmail](https://img.shields.io/badge/Gmail-D14836?logo=gmail&logoColor=white)](mailto:422indani@gmail.com)
[![LinkedIn](https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&logoColor=fff)](https://www.linkedin.com/in/azzindan1/)
[![GitHub Pages](https://img.shields.io/badge/GitHub%20Pages-121013?logo=github&logoColor=white)](https://azzindani.github.io/)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21E?logo=huggingface&logoColor=000)](https://huggingface.co/Azzindani)
[![GitHub](https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white)](https://github.com/azzindani)
---

# üßπ LLM Dataset Preprocessing & Testing

This repository provides tools and notebooks to preprocess, clean, and test datasets before using them for **LLM (Large Language Model)** fine-tuning or evaluation.

The goal is to ensure that datasets are well-structured, tokenization-friendly, and compatible with your LLM training pipeline (e.g., LoRA, SFT, QLoRA).

---

## üîç What This Repo Covers

- ‚úÖ Cleaning and formatting raw text (JSON, CSV, TXT)
- ‚úÖ Converting into prompt-response format
- ‚úÖ Validating structure for Hugging Face `datasets`
- ‚úÖ Previewing token length and instruction style
- ‚úÖ Optional: Sampling for quick evaluation or testing

---
